{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2816dc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniil/programming/diplom/mtrlgnn/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/daniil/programming/diplom/mtrlgnn/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/daniil/programming/diplom/mtrlgnn/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "from rl4co.envs import FJSPEnv\n",
    "from rl4co.envs.scheduling.fjsp.generator import FJSPGenerator\n",
    "\n",
    "from rl4co.models.nn.graph.hgnn import HetGNNEncoder\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816dbe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FJSPGeneratorWithGPM(FJSPGenerator):\n",
    "\n",
    "    def __init__(self, \n",
    "                 num_jobs = 10, \n",
    "                 num_machines = 5, \n",
    "                 min_ops_per_job = 4, \n",
    "                 max_ops_per_job = 6, \n",
    "                 min_processing_time = 1, \n",
    "                 max_processing_time = 20, \n",
    "                 min_eligible_ma_per_op = 1, \n",
    "                 max_eligible_ma_per_op = None, \n",
    "                 same_mean_per_op = True, \n",
    "                 **unused_kwargs):\n",
    "        \n",
    "        super().__init__(num_jobs, \n",
    "                         num_machines, \n",
    "                         min_ops_per_job, \n",
    "                         max_ops_per_job, \n",
    "                         min_processing_time, \n",
    "                         max_processing_time, \n",
    "                         min_eligible_ma_per_op, \n",
    "                         max_eligible_ma_per_op, \n",
    "                         same_mean_per_op, \n",
    "                         **unused_kwargs)\n",
    "\n",
    "    def _generate(self, batch_size):\n",
    "        td = super()._generate(batch_size)\n",
    "\n",
    "        bs, n_machines, n_ops = td[\"proc_times\"].shape\n",
    "\n",
    "        general_purpose_machine = torch.ones(size=(bs, 1, n_ops), \n",
    "                                             dtype=td[\"proc_times\"].dtype, \n",
    "                                             device=td[\"proc_times\"].device) * self.max_processing_time\n",
    "\n",
    "        td[\"proc_times\"] = torch.cat([td[\"proc_times\"], general_purpose_machine], dim=1)\n",
    "\n",
    "        return td\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7b90e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FJSPEnvMOPM(FJSPEnv):\n",
    "    def __init__(self, generator_params = ..., check_mask = False, stepwise_reward = False, **kwargs):\n",
    "\n",
    "        generator_params = {**generator_params}\n",
    "        self.max_ops_processed = generator_params.pop(\"max_ops_processed\")\n",
    "\n",
    "        generator = FJSPGeneratorWithGPM(**generator_params)\n",
    "\n",
    "        super().__init__(generator=generator, mask_no_ops=True, check_mask=check_mask, stepwise_reward=stepwise_reward, **kwargs)\n",
    "\n",
    "    def _reset(self, td = None, batch_size=None):\n",
    "        td = super()._reset(td, batch_size)\n",
    "\n",
    "        ma_ops_processed_left = torch.ones_like(td[\"busy_until\"]) * self.max_ops_processed\n",
    "\n",
    "        td[\"ma_ops_processed_left\"] = ma_ops_processed_left\n",
    "\n",
    "        td[\"ma_ops_processed_left\"][:, -1] = 1e6\n",
    "\n",
    "        return td.to(self.device)\n",
    "    \n",
    "    def _step(self, td):\n",
    "\n",
    "        td = td.to(self.device)\n",
    "\n",
    "        # test if we can use new action\n",
    "\n",
    "        n_batches, n_jobs = td[\"end_op_per_job\"].shape\n",
    "\n",
    "        ma_ops_processed_left = td[\"ma_ops_processed_left\"]\n",
    "\n",
    "        n_machines = ma_ops_processed_left.size(1)\n",
    "\n",
    "        machines = (td[\"action\"] - 1) % n_machines\n",
    "\n",
    "        ma_ops_processed_left[torch.arange(ma_ops_processed_left.size(0), device=self.device)[td[\"action\"] > 0], machines[td[\"action\"] > 0]] -= 1\n",
    "\n",
    "        assert (ma_ops_processed_left >= 0).all()\n",
    "\n",
    "        td = super()._step(td)\n",
    "\n",
    "        td[\"ma_ops_processed_left\"] = ma_ops_processed_left\n",
    "\n",
    "        availible_machines_mask = (ma_ops_processed_left > 0)\n",
    "\n",
    "        new_mask = torch.concat([torch.tensor([True], device=self.device).bool().repeat(n_batches, 1), availible_machines_mask.repeat(1, n_jobs)], dim=1)\n",
    "\n",
    "        new_mask = td[\"action_mask\"] * new_mask\n",
    "\n",
    "        all_false_rows = ~new_mask.any(dim=1)\n",
    "\n",
    "        new_mask[all_false_rows, 0] = True\n",
    "\n",
    "        td[\"action_mask\"] = new_mask\n",
    "\n",
    "        return td\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9327e014",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FJSPEnvMTPM(FJSPEnv):\n",
    "    def __init__(self, generator_params = ..., check_mask = False, stepwise_reward = False, **kwargs):\n",
    "\n",
    "        generator_params = {**generator_params}\n",
    "        self.max_time_worked = generator_params.pop(\"max_time_worked\")\n",
    "\n",
    "        generator = FJSPGeneratorWithGPM(**generator_params)\n",
    "\n",
    "        super().__init__(generator=generator, mask_no_ops=True, check_mask=check_mask, stepwise_reward=stepwise_reward, **kwargs)\n",
    "\n",
    "    def _reset(self, td = None, batch_size=None):\n",
    "        td = super()._reset(td, batch_size)\n",
    "\n",
    "        ma_time_left = torch.ones_like(td[\"busy_until\"]) * self.max_time_worked\n",
    "\n",
    "        td[\"ma_time_left\"] = ma_time_left\n",
    "\n",
    "        td[\"ma_time_left\"][:, -1] = 1e6\n",
    "\n",
    "        return td.to(self.device)\n",
    "    \n",
    "    def _step(self, td):\n",
    "\n",
    "        td = td.to(self.device)\n",
    "\n",
    "        # test if we can use new action\n",
    "\n",
    "        n_batches, n_jobs = td[\"end_op_per_job\"].shape\n",
    "\n",
    "        ma_time_left = td[\"ma_time_left\"]\n",
    "\n",
    "        n_machines = ma_time_left.size(1)\n",
    "\n",
    "        machines = (td[\"action\"] - 1) % n_machines\n",
    "\n",
    "        jobs = (td[\"action\"] - 1) // n_machines\n",
    "\n",
    "        ops = td[\"next_op\"][torch.arange(n_batches), jobs]\n",
    "\n",
    "        ops_time = td[\"proc_times\"][torch.arange(n_batches), machines, ops]\n",
    "\n",
    "        ma_time_left[torch.arange(ma_time_left.size(0), device=self.device)[td[\"action\"] > 0], machines[td[\"action\"] > 0]] -= ops_time.flatten()[td[\"action\"] > 0]\n",
    "\n",
    "        assert (ma_time_left >= 0).all()\n",
    "\n",
    "        td = super()._step(td)\n",
    "\n",
    "        td[\"ma_time_left\"] = ma_time_left\n",
    "\n",
    "        batches, available_jobs, available_machines = torch.where(td[\"action_mask\"][:, 1:].reshape(n_batches, n_jobs, n_machines))\n",
    "\n",
    "        ops = td[\"next_op\"][batches, available_jobs]\n",
    "\n",
    "        ops_time = td[\"proc_times\"][batches, available_machines, ops]\n",
    "\n",
    "        available_ops_mask = (ma_time_left[batches, available_machines] > ops_time)\n",
    "\n",
    "        new_mask = torch.ones(size=(n_batches, n_jobs, n_machines), dtype=bool, device=self.device)\n",
    "\n",
    "        new_mask[batches, available_jobs, available_machines] = available_ops_mask\n",
    "\n",
    "        new_mask = new_mask.reshape(n_batches, -1)\n",
    "\n",
    "        new_mask = torch.concat([torch.tensor([True], device=self.device).bool().repeat(n_batches, 1), new_mask], dim=1)\n",
    "\n",
    "        new_mask *= td[\"action_mask\"]\n",
    "\n",
    "        all_false_rows = ~new_mask.any(dim=1)\n",
    "\n",
    "        new_mask[all_false_rows, 0] = True\n",
    "        \n",
    "        td[\"action_mask\"] = new_mask\n",
    "\n",
    "        return td\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0af30354",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_params = {\n",
    "  \"num_jobs\": 20,  # the total number of jobs\n",
    "  \"num_machines\": 10,  # the total number of machines that can process operations\n",
    "  \"min_ops_per_job\": 1,  # minimum number of operatios per job\n",
    "  \"max_ops_per_job\": 5,  # maximum number of operations per job\n",
    "  \"min_processing_time\": 1,  # the minimum time required for a machine to process an operation\n",
    "  \"max_processing_time\": 20,  # the maximum time required for a machine to process an operation\n",
    "  \"min_eligible_ma_per_op\": 1,  # the minimum number of machines capable to process an operation\n",
    "  \"max_eligible_ma_per_op\": 5,  # the maximum number of machines capable to process an operation\n",
    "}\n",
    "\n",
    "new_generator_params = {**generator_params}\n",
    "new_generator_params[\"max_ops_processed\"] = 6\n",
    "new_generator_params[\"max_time_worked\"] = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2776b590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 1 unused kwargs: {'max_time_worked': 60}\n",
      "Found 2 unused kwargs: {'max_ops_processed': 6, 'max_time_worked': 60}\n"
     ]
    }
   ],
   "source": [
    "new_env = FJSPEnvMOPM(generator_params=new_generator_params)\n",
    "\n",
    "env = FJSPEnv(generator_params=new_generator_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab613279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl4co.models.zoo.l2d import L2DPolicy, L2DModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f7d0270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpu'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    accelerator = \"gpu\"\n",
    "    batch_size = 64\n",
    "    train_data_size = 5_000\n",
    "    embed_dim = 64\n",
    "    num_encoder_layers = 8\n",
    "else:\n",
    "    accelerator = \"cpu\"\n",
    "    batch_size = 32\n",
    "    train_data_size = 1_000\n",
    "    embed_dim = 64\n",
    "    num_encoder_layers = 2\n",
    "\n",
    "accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cb7d576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accelerator = \"cpu\"\n",
    "batch_size = 32\n",
    "train_data_size = 1_000\n",
    "embed_dim = 64\n",
    "num_encoder_layers = 2\n",
    "\n",
    "accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db9fbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniil/programming/diplom/mtrlgnn/.venv/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'env' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['env'])`.\n",
      "/home/daniil/programming/diplom/mtrlgnn/.venv/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'policy' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['policy'])`.\n"
     ]
    }
   ],
   "source": [
    "model = L2DModel(env,\n",
    "                 baseline=\"rollout\",\n",
    "                 batch_size=batch_size,\n",
    "                 train_data_size=train_data_size,\n",
    "                 val_data_size=1_000,\n",
    "                 optimizer_kwargs={\"lr\": 1e-5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bf10024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-92.7656), tensor(-125.3594))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_new = new_env.reset(batch_size=64)\n",
    "\n",
    "td = env.reset(batch_size=64)\n",
    "\n",
    "res = model(td, env=env)\n",
    "\n",
    "res_new = model(td_new, env=new_env)\n",
    "\n",
    "res[\"reward\"].mean(), res_new[\"reward\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "726279f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniil/programming/diplom/mtrlgnn/.venv/lib/python3.10/site-packages/lightning/pytorch/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['baseline.baseline.policy.encoder.init_embedding.init_ops_embed.weight', 'baseline.baseline.policy.encoder.init_embedding.pos_encoder.pe', 'baseline.baseline.policy.encoder.init_embedding.init_ma_embed.weight', 'baseline.baseline.policy.encoder.init_embedding.edge_embed.weight', 'baseline.baseline.policy.encoder.layers.0.hgnn1.self_attn', 'baseline.baseline.policy.encoder.layers.0.hgnn1.cross_attn', 'baseline.baseline.policy.encoder.layers.0.hgnn1.edge_attn', 'baseline.baseline.policy.encoder.layers.0.hgnn2.self_attn', 'baseline.baseline.policy.encoder.layers.0.hgnn2.cross_attn', 'baseline.baseline.policy.encoder.layers.0.hgnn2.edge_attn', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm1.normalizer.weight', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm1.normalizer.bias', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm1.normalizer.running_mean', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm1.normalizer.running_var', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm1.normalizer.num_batches_tracked', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.ffn.0.weight', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.ffn.0.bias', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.ffn.2.weight', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.ffn.2.bias', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm2.normalizer.weight', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm2.normalizer.bias', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm2.normalizer.running_mean', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm2.normalizer.running_var', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm2.normalizer.num_batches_tracked', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm1.normalizer.weight', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm1.normalizer.bias', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm1.normalizer.running_mean', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm1.normalizer.running_var', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm1.normalizer.num_batches_tracked', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.ffn.0.weight', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.ffn.0.bias', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.ffn.2.weight', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.ffn.2.bias', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm2.normalizer.weight', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm2.normalizer.bias', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm2.normalizer.running_mean', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm2.normalizer.running_var', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm2.normalizer.num_batches_tracked', 'baseline.baseline.policy.encoder.layers.1.hgnn1.self_attn', 'baseline.baseline.policy.encoder.layers.1.hgnn1.cross_attn', 'baseline.baseline.policy.encoder.layers.1.hgnn1.edge_attn', 'baseline.baseline.policy.encoder.layers.1.hgnn2.self_attn', 'baseline.baseline.policy.encoder.layers.1.hgnn2.cross_attn', 'baseline.baseline.policy.encoder.layers.1.hgnn2.edge_attn', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm1.normalizer.weight', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm1.normalizer.bias', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm1.normalizer.running_mean', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm1.normalizer.running_var', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm1.normalizer.num_batches_tracked', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.ffn.0.weight', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.ffn.0.bias', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.ffn.2.weight', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.ffn.2.bias', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm2.normalizer.weight', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm2.normalizer.bias', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm2.normalizer.running_mean', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm2.normalizer.running_var', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm2.normalizer.num_batches_tracked', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm1.normalizer.weight', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm1.normalizer.bias', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm1.normalizer.running_mean', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm1.normalizer.running_var', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm1.normalizer.num_batches_tracked', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.ffn.0.weight', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.ffn.0.bias', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.ffn.2.weight', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.ffn.2.bias', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm2.normalizer.weight', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm2.normalizer.bias', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm2.normalizer.running_mean', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm2.normalizer.running_var', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm2.normalizer.num_batches_tracked', 'baseline.baseline.policy.decoder.actor.dummy', 'baseline.baseline.policy.decoder.actor.mlp.lins.0.weight', 'baseline.baseline.policy.decoder.actor.mlp.lins.0.bias', 'baseline.baseline.policy.decoder.actor.mlp.lins.1.weight', 'baseline.baseline.policy.decoder.actor.mlp.lins.1.bias', 'baseline.baseline.policy.decoder.actor.mlp.lins.2.weight', 'baseline.baseline.policy.decoder.actor.mlp.lins.2.bias']\n"
     ]
    }
   ],
   "source": [
    "model_load = L2DModel.load_from_checkpoint(\"./logs/csv_logs/version_0/checkpoints/epoch=19-step=400.ckpt\", map_location=\"cpu\", load_baseline=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e374ff04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-91.0781), tensor(-118.2344))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_new = new_env.reset(batch_size=64)\n",
    "\n",
    "td = env.reset(batch_size=64)\n",
    "\n",
    "res = model(td, env=env)\n",
    "\n",
    "res_new = model(td_new, env=new_env)\n",
    "\n",
    "res[\"reward\"].mean(), res_new[\"reward\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fed47c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = L2DModel(new_env,\n",
    "                 baseline=\"rollout\",\n",
    "                 batch_size=batch_size,\n",
    "                 train_data_size=train_data_size,\n",
    "                 val_data_size=1_000,\n",
    "                 optimizer_kwargs={\"lr\": 1e-5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb7c4e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11e3759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loggers = [\n",
    "        CSVLogger(save_dir=\"logs_ver2\", name=\"csv_logs\"),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3573f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl4co.utils.trainer import RL4COTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9489950d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniil/programming/diplom/mtrlgnn/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:513: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "/home/daniil/programming/diplom/mtrlgnn/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:734: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = RL4COTrainer(\n",
    "    max_epochs=3,\n",
    "    accelerator=accelerator,\n",
    "    devices=1,\n",
    "    logger=loggers,\n",
    "    log_every_n_steps=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4aa832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "\n",
      "  | Name     | Type           | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | env      | FJSPEnvMOPM    | 0      | train\n",
      "1 | policy   | L2DPolicy      | 81.2 K | train\n",
      "2 | baseline | WarmupBaseline | 81.2 K | train\n",
      "----------------------------------------------------\n",
      "162 K     Trainable params\n",
      "0         Non-trainable params\n",
      "162 K     Total params\n",
      "0.649     Total estimated model params size (MB)\n",
      "74        Modules in train mode\n",
      "70        Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ecf7b96ec8453887d48de8913b4e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniil/programming/diplom/mtrlgnn/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/daniil/programming/diplom/mtrlgnn/.venv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42486b675767427fb19b65742f4d1f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1cc682865d4ff389bd88dfa1fa4363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368cdd3ab04d42dbbe7b83e89d05f101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635372b6533746f9a2c96bb021be2af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2135045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a2636e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = pd.read_csv(\"./logs_ver2/csv_logs/version_2/metrics.csv\")\n",
    "metrics = pd.read_csv(\"./logs_ver2/csv_logs/version_6/metrics.csv\")\n",
    "metrics[\"val/reward\"] = -metrics[\"val/reward\"].shift(-1)\n",
    "metrics[\"train/reward\"] = -metrics[\"train/reward\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3abbda6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=train/reward<br>step=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "train/reward",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "train/reward",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "EztP",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAADoY0AAAAAAANxgQAAAAAAA7WFA",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=val/reward<br>step=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "val/reward",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "val/reward",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "EztP",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAYDvTYUAAAACAk2RhQAAAAKBwVWFA",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "step"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.line(data_frame=metrics.dropna(), x=\"step\", y=[\"train/reward\", \"val/reward\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c48997c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiEncoder(nn.Module):\n",
    "    def __init__(self, encoder_1, encoder_2, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.encoder_1 = encoder_1\n",
    "        self.encoder_2 = encoder_2\n",
    "\n",
    "    def forward(self, td):\n",
    "\n",
    "        hidden_1, _ = self.encoder_1(td)\n",
    "\n",
    "        hidden_2, _ = self.encoder_2(td)\n",
    "\n",
    "        hidden = (hidden_1[0] + hidden_2[0], hidden_1[1] + hidden_2[1])\n",
    "\n",
    "        return hidden, None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52f5dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditionalMachineInfoInitEmbedding(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim,\n",
    "        feature_name: str,\n",
    "        feature_dim: int = 1,\n",
    "        linear_bias: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.feature_name = feature_name\n",
    "        self.embed_dim = embed_dim\n",
    "        self.init_embed = nn.Linear(feature_dim, embed_dim, linear_bias)\n",
    "\n",
    "    def forward(self, td):\n",
    "        bs, n_ops = td[\"is_ready\"].shape\n",
    "        ops_emb = torch.randn(size=(bs, n_ops, self.embed_dim), device=td.device)\n",
    "        ma_emb = self.init_embed(td[self.feature_name].unsqueeze(2))\n",
    "        n_machines = ma_emb.size(1)\n",
    "        edge_emb = torch.randn(size=(bs, n_ops, n_machines, self.embed_dim), device=td.device)\n",
    "        edges = td[\"ops_ma_adj\"].transpose(1, 2).to(td.device)\n",
    "\n",
    "        return ops_emb, ma_emb, edge_emb, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28df7867",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_new = new_env.reset(batch_size=32).to(\"cpu\")\n",
    "\n",
    "encoder_1 = HetGNNEncoder(embed_dim=64, num_layers=2).to(\"cpu\")\n",
    "encoder_2 = HetGNNEncoder(embed_dim=64, num_layers=2, init_embedding=AdditionalMachineInfoInitEmbedding(64, \"ma_ops_processed_left\")).to(\"cpu\")\n",
    "\n",
    "enc = MultiEncoder(encoder_1, encoder_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c80bf512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[[ 0.0256,  1.5537,  1.4121,  ...,  0.8951, -0.2414,  0.1412],\n",
       "           [ 0.3411,  1.3600,  2.4849,  ..., -0.8661,  0.4525, -1.2002],\n",
       "           [ 0.7006,  0.7042,  0.7436,  ..., -0.9510, -0.5729, -0.8725],\n",
       "           ...,\n",
       "           [-1.2652,  0.6114, -0.8459,  ..., -1.2724,  1.6238,  3.0824],\n",
       "           [-0.2696,  1.1248, -1.8480,  ..., -0.0999,  0.5549,  3.4904],\n",
       "           [-0.1094,  1.5792, -1.7397,  ..., -2.3945,  1.8959,  2.4251]],\n",
       "  \n",
       "          [[ 2.5619,  2.6316, -0.4933,  ..., -0.4808,  0.8992,  0.1865],\n",
       "           [ 2.1542,  0.6454,  2.3940,  ..., -1.3039, -1.1708,  0.1922],\n",
       "           [ 1.9572,  0.7328,  0.9534,  ..., -0.6537, -0.2140,  0.2837],\n",
       "           ...,\n",
       "           [-0.2552,  0.1444, -1.3306,  ..., -2.8001,  1.0467,  1.1371],\n",
       "           [-0.3360, -1.3910, -2.1305,  ..., -1.0960,  0.9125,  1.4524],\n",
       "           [ 0.5688,  2.4287, -1.8332,  ..., -2.2809, -0.0669,  3.0594]],\n",
       "  \n",
       "          [[ 0.9161, -1.2487,  0.2975,  ..., -2.7695,  0.0579,  1.6607],\n",
       "           [ 2.3800,  1.9628,  0.2956,  ..., -1.7341,  0.0879,  1.0881],\n",
       "           [ 2.3018,  2.1489,  0.0342,  ..., -1.1921,  0.2005,  0.3015],\n",
       "           ...,\n",
       "           [-1.0832, -0.1298, -3.3188,  ..., -2.0281,  0.0075,  0.4121],\n",
       "           [ 1.6673,  1.1650, -0.5571,  ..., -1.7455,  3.1396,  2.5274],\n",
       "           [-0.5365,  1.3217, -1.6555,  ..., -1.9008,  0.4180,  2.4116]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 1.5873,  2.6568,  1.3667,  ..., -0.2076, -1.0528,  0.1991],\n",
       "           [ 2.7059,  1.2076,  1.8383,  ...,  0.7734, -0.2599,  1.2853],\n",
       "           [ 1.5288,  1.0185,  1.8682,  ..., -1.0501, -0.4737, -0.8600],\n",
       "           ...,\n",
       "           [ 0.7342, -0.0689, -1.4992,  ..., -0.2556,  0.9011,  0.3231],\n",
       "           [ 2.1527,  1.7395, -0.3804,  ...,  0.3846, -0.3236,  2.6704],\n",
       "           [ 1.7097,  0.5550, -0.4273,  ..., -2.2850,  1.2799,  1.0299]],\n",
       "  \n",
       "          [[ 1.1621,  0.7309,  1.4217,  ..., -1.1433, -0.2997,  0.8328],\n",
       "           [ 0.2083,  0.5950,  1.5241,  ...,  1.9162, -0.5524, -0.5522],\n",
       "           [ 2.0335,  0.0791,  0.7362,  ...,  0.1327, -0.8498, -1.0416],\n",
       "           ...,\n",
       "           [-1.4421,  1.3044,  0.0547,  ..., -0.0270, -0.2726,  0.3332],\n",
       "           [ 0.0677, -0.8271,  0.1337,  ..., -0.1061,  1.2060, -0.9505],\n",
       "           [ 0.0659, -0.1925, -1.0946,  ..., -0.3114,  2.4145,  0.3009]],\n",
       "  \n",
       "          [[ 1.5014,  2.3539,  0.4273,  ..., -0.2299, -1.2725, -0.1059],\n",
       "           [ 2.4963,  0.8568,  1.6475,  ..., -2.5999,  2.2818,  0.9354],\n",
       "           [ 1.3231,  0.7056,  2.2219,  ...,  0.7247, -0.4227, -0.7830],\n",
       "           ...,\n",
       "           [-0.7973,  0.6411,  0.7418,  ..., -1.1158,  1.7117,  1.0979],\n",
       "           [-1.1244,  1.2096, -0.4124,  ..., -0.0511, -0.9311,  2.6268],\n",
       "           [-0.7420,  0.0313, -1.4065,  ..., -1.8914,  1.0309,  0.8185]]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[[-1.1600e-01, -4.2069e-01,  4.4830e-01,  ...,  1.0585e+00,\n",
       "            -1.4894e+00, -7.5888e-01],\n",
       "           [-4.3267e-01,  4.2804e-01,  5.4957e-01,  ...,  1.6504e-01,\n",
       "            -2.5582e-01, -1.4922e-01],\n",
       "           [-1.8533e+00,  8.7451e-01,  1.0758e-01,  ...,  9.1136e-01,\n",
       "            -1.0546e+00, -1.5200e-01],\n",
       "           ...,\n",
       "           [-5.3978e-01,  2.1375e-03,  7.5820e-01,  ...,  4.9908e-01,\n",
       "            -8.1585e-01, -1.1708e+00],\n",
       "           [ 7.1248e-01,  6.0185e-01,  8.5115e-01,  ..., -1.2626e+00,\n",
       "             3.1390e-01,  2.2789e-01],\n",
       "           [ 2.6212e+00, -1.2776e+00, -4.2363e+00,  ..., -3.7294e+00,\n",
       "             3.8233e+00,  3.7772e+00]],\n",
       "  \n",
       "          [[-7.6729e-01,  1.7414e+00, -8.7515e-01,  ..., -4.2550e-01,\n",
       "            -4.6721e-01,  1.5966e-01],\n",
       "           [-9.5661e-02,  1.2573e-01,  1.1222e+00,  ...,  2.9899e-02,\n",
       "            -1.9678e-01, -3.8248e-01],\n",
       "           [ 5.8782e-01,  1.4452e+00,  8.5944e-02,  ..., -6.2010e-01,\n",
       "            -8.7813e-02,  6.8150e-01],\n",
       "           ...,\n",
       "           [ 7.6760e-01,  7.7921e-01,  7.1300e-02,  ..., -1.6662e-02,\n",
       "            -3.8803e-01,  3.8340e-01],\n",
       "           [-1.5742e-01,  9.7744e-01,  3.7213e-01,  ..., -9.3972e-02,\n",
       "            -2.1605e-01, -2.3179e-01],\n",
       "           [ 1.9683e+00, -1.5393e+00, -5.6065e+00,  ..., -3.6263e+00,\n",
       "             3.4261e+00,  4.4475e+00]],\n",
       "  \n",
       "          [[ 4.6650e-02,  1.3826e+00, -1.1528e-01,  ..., -1.6149e+00,\n",
       "             1.0685e+00,  8.4268e-01],\n",
       "           [-1.1482e+00, -9.7298e-01,  1.9346e-01,  ...,  2.8668e-01,\n",
       "            -1.4382e+00, -1.1597e+00],\n",
       "           [-1.5204e+00, -3.3783e-01, -1.8640e-01,  ..., -4.1980e-01,\n",
       "            -9.1835e-01, -6.0013e-01],\n",
       "           ...,\n",
       "           [-1.1968e+00,  5.6783e-01, -3.8802e-01,  ...,  2.8711e-01,\n",
       "            -4.1830e-01, -4.4143e-01],\n",
       "           [-6.9468e-01,  1.7202e+00, -1.8459e+00,  ...,  6.8456e-02,\n",
       "            -8.5397e-01,  7.2680e-01],\n",
       "           [ 2.3258e+00, -1.3461e+00, -5.0227e+00,  ..., -3.8052e+00,\n",
       "             4.0128e+00,  4.4912e+00]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 3.1934e-01,  6.5883e-01,  6.6661e-01,  ..., -6.5542e-01,\n",
       "            -4.0565e-02, -1.3045e-01],\n",
       "           [-6.2108e-01, -5.8225e-01, -3.8613e-01,  ...,  1.3765e+00,\n",
       "            -1.3665e+00, -9.8700e-01],\n",
       "           [ 6.0813e-01,  6.0162e-01,  6.5421e-01,  ..., -3.5249e-01,\n",
       "             5.6010e-01, -2.9673e-01],\n",
       "           ...,\n",
       "           [-5.4934e-03, -1.0523e+00,  1.3257e+00,  ...,  1.4117e+00,\n",
       "            -9.7515e-01, -1.6672e+00],\n",
       "           [-8.5558e-01, -4.9070e-01,  9.9321e-01,  ...,  6.5773e-01,\n",
       "            -5.1236e-01, -2.7645e-01],\n",
       "           [ 2.7582e+00, -1.8688e+00, -4.9970e+00,  ..., -3.6300e+00,\n",
       "             3.1541e+00,  3.9729e+00]],\n",
       "  \n",
       "          [[ 2.3990e-01, -8.4202e-01,  1.8686e+00,  ...,  1.8723e+00,\n",
       "            -1.4369e+00, -1.5820e+00],\n",
       "           [-1.1048e+00, -3.9979e-01,  1.0261e+00,  ...,  8.8086e-01,\n",
       "            -7.2738e-01, -1.5108e+00],\n",
       "           [-1.8180e+00, -5.9924e-01,  4.0605e-01,  ...,  9.8571e-01,\n",
       "            -4.5617e-01, -7.0526e-01],\n",
       "           ...,\n",
       "           [-3.5267e-01,  8.8786e-01, -3.4804e-01,  ..., -6.4055e-01,\n",
       "             5.0386e-01,  4.3825e-01],\n",
       "           [-6.4228e-01, -8.7952e-01,  9.9074e-01,  ...,  2.3393e+00,\n",
       "            -2.2511e+00, -2.0858e+00],\n",
       "           [ 1.8038e+00, -2.0297e+00, -4.8935e+00,  ..., -3.3630e+00,\n",
       "             2.7631e+00,  3.2222e+00]],\n",
       "  \n",
       "          [[-4.4149e-01,  5.9372e-01, -9.2809e-03,  ...,  8.5528e-01,\n",
       "            -5.2375e-01, -6.5834e-01],\n",
       "           [-1.7380e+00, -7.2976e-01,  3.1346e-01,  ...,  2.0900e+00,\n",
       "            -1.6865e+00, -1.3107e+00],\n",
       "           [-4.0222e-02,  4.3888e-01,  1.8169e+00,  ...,  8.2525e-01,\n",
       "             7.5840e-01, -2.2080e-01],\n",
       "           ...,\n",
       "           [-6.9137e-01, -7.4544e-01,  9.9158e-01,  ...,  8.8371e-01,\n",
       "            -1.1393e+00, -9.2510e-01],\n",
       "           [-4.7986e-02, -1.1250e+00,  1.8690e+00,  ...,  1.3331e+00,\n",
       "            -1.6916e+00, -1.3066e+00],\n",
       "           [ 2.3682e+00, -2.0246e+00, -4.6289e+00,  ..., -3.5902e+00,\n",
       "             3.1916e+00,  3.4500e+00]]], grad_fn=<AddBackward0>)),\n",
       " None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc(td_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6909f73d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd774f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniil/programming/diplom/mtrlgnn/.venv/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: UserWarning:\n",
      "\n",
      "Attribute 'env' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['env'])`.\n",
      "\n",
      "/home/daniil/programming/diplom/mtrlgnn/.venv/lib/python3.10/site-packages/lightning/pytorch/utilities/parsing.py:209: UserWarning:\n",
      "\n",
      "Attribute 'policy' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['policy'])`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = L2DModel(new_env,\n",
    "                 baseline=\"rollout\",\n",
    "                 batch_size=32,\n",
    "                 train_data_size=1000,\n",
    "                 val_data_size=1_000,\n",
    "                 optimizer_kwargs={\"lr\": 1e-5}, \n",
    "                 policy_kwargs={\"encoder\": enc, \"embed_dim\": 64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca9b9c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_old = L2DModel(new_env,\n",
    "                 baseline=\"rollout\",\n",
    "                 batch_size=32,\n",
    "                 train_data_size=1000,\n",
    "                 val_data_size=1_000,\n",
    "                 optimizer_kwargs={\"lr\": 1e-5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d65b0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniil/programming/diplom/mtrlgnn/.venv/lib/python3.10/site-packages/lightning/pytorch/core/saving.py:195: UserWarning:\n",
      "\n",
      "Found keys that are not in the model state dict but in the checkpoint: ['baseline.baseline.policy.encoder.init_embedding.init_ops_embed.weight', 'baseline.baseline.policy.encoder.init_embedding.pos_encoder.pe', 'baseline.baseline.policy.encoder.init_embedding.init_ma_embed.weight', 'baseline.baseline.policy.encoder.init_embedding.edge_embed.weight', 'baseline.baseline.policy.encoder.layers.0.hgnn1.self_attn', 'baseline.baseline.policy.encoder.layers.0.hgnn1.cross_attn', 'baseline.baseline.policy.encoder.layers.0.hgnn1.edge_attn', 'baseline.baseline.policy.encoder.layers.0.hgnn2.self_attn', 'baseline.baseline.policy.encoder.layers.0.hgnn2.cross_attn', 'baseline.baseline.policy.encoder.layers.0.hgnn2.edge_attn', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm1.normalizer.weight', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm1.normalizer.bias', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm1.normalizer.running_mean', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm1.normalizer.running_var', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm1.normalizer.num_batches_tracked', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.ffn.0.weight', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.ffn.0.bias', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.ffn.2.weight', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.ffn.2.bias', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm2.normalizer.weight', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm2.normalizer.bias', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm2.normalizer.running_mean', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm2.normalizer.running_var', 'baseline.baseline.policy.encoder.layers.0.ffn1.ops.norm2.normalizer.num_batches_tracked', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm1.normalizer.weight', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm1.normalizer.bias', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm1.normalizer.running_mean', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm1.normalizer.running_var', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm1.normalizer.num_batches_tracked', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.ffn.0.weight', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.ffn.0.bias', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.ffn.2.weight', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.ffn.2.bias', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm2.normalizer.weight', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm2.normalizer.bias', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm2.normalizer.running_mean', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm2.normalizer.running_var', 'baseline.baseline.policy.encoder.layers.0.ffn2.ops.norm2.normalizer.num_batches_tracked', 'baseline.baseline.policy.encoder.layers.1.hgnn1.self_attn', 'baseline.baseline.policy.encoder.layers.1.hgnn1.cross_attn', 'baseline.baseline.policy.encoder.layers.1.hgnn1.edge_attn', 'baseline.baseline.policy.encoder.layers.1.hgnn2.self_attn', 'baseline.baseline.policy.encoder.layers.1.hgnn2.cross_attn', 'baseline.baseline.policy.encoder.layers.1.hgnn2.edge_attn', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm1.normalizer.weight', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm1.normalizer.bias', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm1.normalizer.running_mean', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm1.normalizer.running_var', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm1.normalizer.num_batches_tracked', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.ffn.0.weight', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.ffn.0.bias', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.ffn.2.weight', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.ffn.2.bias', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm2.normalizer.weight', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm2.normalizer.bias', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm2.normalizer.running_mean', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm2.normalizer.running_var', 'baseline.baseline.policy.encoder.layers.1.ffn1.ops.norm2.normalizer.num_batches_tracked', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm1.normalizer.weight', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm1.normalizer.bias', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm1.normalizer.running_mean', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm1.normalizer.running_var', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm1.normalizer.num_batches_tracked', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.ffn.0.weight', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.ffn.0.bias', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.ffn.2.weight', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.ffn.2.bias', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm2.normalizer.weight', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm2.normalizer.bias', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm2.normalizer.running_mean', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm2.normalizer.running_var', 'baseline.baseline.policy.encoder.layers.1.ffn2.ops.norm2.normalizer.num_batches_tracked', 'baseline.baseline.policy.decoder.actor.dummy', 'baseline.baseline.policy.decoder.actor.mlp.lins.0.weight', 'baseline.baseline.policy.decoder.actor.mlp.lins.0.bias', 'baseline.baseline.policy.decoder.actor.mlp.lins.1.weight', 'baseline.baseline.policy.decoder.actor.mlp.lins.1.bias', 'baseline.baseline.policy.decoder.actor.mlp.lins.2.weight', 'baseline.baseline.policy.decoder.actor.mlp.lins.2.bias']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_load_2 = L2DModel.load_from_checkpoint(\"./logs_ver2/csv_logs/version_2/checkpoints/epoch=19-step=1580.ckpt\", map_location=\"cpu\", load_baseline=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5280b8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-123.5312), tensor(-123.5469), tensor(-118.1875), tensor(-114.6094))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_new = new_env.reset(batch_size=64)\n",
    "\n",
    "res_new = model(td_new, env=new_env)\n",
    "\n",
    "td_new = new_env.reset(td_new)\n",
    "\n",
    "res_old = model_old(td_new, env=new_env)\n",
    "\n",
    "td_new = new_env.reset(td_new)\n",
    "\n",
    "res_load = model_load(td_new, env=new_env)\n",
    "\n",
    "td_new = new_env.reset(td_new)\n",
    "\n",
    "res_load_2 = model_load_2(td_new, env=new_env)\n",
    "\n",
    "res_new[\"reward\"].mean(), res_old[\"reward\"].mean(), res_load[\"reward\"].mean(), res_load_2[\"reward\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bced84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_1 = HetGNNEncoder(embed_dim=16, num_layers=8)\n",
    "encoder_2 = HetGNNEncoder(embed_dim=16, num_layers=4, init_embedding=AdditionalMachineInfoInitEmbedding(16, \"ma_ops_processed_left\"))\n",
    "\n",
    "enc = MultiEncoder(encoder_1, encoder_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "908e21ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-145.3438)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_new = new_env.reset(batch_size=64)\n",
    "\n",
    "res_new = model.to(\"cpu\")(td_new.to(\"cpu\"), env=new_env.to(\"cpu\"))\n",
    "\n",
    "res_new[\"reward\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a3506b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = RL4COTrainer(\n",
    "    max_epochs=3,\n",
    "    accelerator=accelerator,\n",
    "    devices=1,\n",
    "    logger=loggers,\n",
    "    log_every_n_steps=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47cfdf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = L2DModel(new_env,\n",
    "                 baseline=\"rollout\",\n",
    "                 batch_size=32,\n",
    "                 train_data_size=1000,\n",
    "                 val_data_size=1_000,\n",
    "                 optimizer_kwargs={\"lr\": 1e-5}, \n",
    "                 policy_kwargs={\"encoder\": enc, \"embed_dim\": 16}).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e059cde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_file not set. Generating dataset instead\n",
      "test_file not set. Generating dataset instead\n",
      "\n",
      "  | Name     | Type           | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | env      | FJSPEnvMOPM    | 0      | train\n",
      "1 | policy   | L2DPolicy      | 29.4 K | train\n",
      "2 | baseline | WarmupBaseline | 29.4 K | train\n",
      "----------------------------------------------------\n",
      "58.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "58.8 K    Total params\n",
      "0.235     Total estimated model params size (MB)\n",
      "329       Modules in train mode\n",
      "325       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf84928f0eef457a88c2e6dd1904991f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8daaef70aff040de822b0de2f466afd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d074b5cacb1f4151964b9895c3a09f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aded5802a9804de88ad35fe223ccbf08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f903c4fa966f4b80a3570e2a8f0606c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5550985e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L2DModel(\n",
       "  (env): FJSPEnvMOPM()\n",
       "  (policy): L2DPolicy(\n",
       "    (encoder): MultiEncoder(\n",
       "      (encoder_1): HetGNNEncoder(\n",
       "        (init_embedding): FJSPInitEmbedding(\n",
       "          (init_ops_embed): Linear(in_features=5, out_features=16, bias=False)\n",
       "          (pos_encoder): PositionalEncoding(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (init_ma_embed): Linear(in_features=1, out_features=16, bias=False)\n",
       "          (edge_embed): Linear(in_features=1, out_features=16, bias=False)\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0-7): 8 x HetGNNBlock(\n",
       "            (hgnn1): HetGNNLayer(\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (hgnn2): HetGNNLayer(\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (ffn1): TransformerFFN(\n",
       "              (ops): ModuleDict(\n",
       "                (norm1): Normalization(\n",
       "                  (normalizer): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (ffn): Sequential(\n",
       "                  (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "                  (1): ReLU()\n",
       "                  (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "                )\n",
       "                (norm2): Normalization(\n",
       "                  (normalizer): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (ffn2): TransformerFFN(\n",
       "              (ops): ModuleDict(\n",
       "                (norm1): Normalization(\n",
       "                  (normalizer): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (ffn): Sequential(\n",
       "                  (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "                  (1): ReLU()\n",
       "                  (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "                )\n",
       "                (norm2): Normalization(\n",
       "                  (normalizer): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (encoder_2): HetGNNEncoder(\n",
       "        (init_embedding): AdditionalMachineInfoInitEmbedding(\n",
       "          (init_embed): Linear(in_features=1, out_features=16, bias=True)\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0-3): 4 x HetGNNBlock(\n",
       "            (hgnn1): HetGNNLayer(\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (hgnn2): HetGNNLayer(\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (ffn1): TransformerFFN(\n",
       "              (ops): ModuleDict(\n",
       "                (norm1): Normalization(\n",
       "                  (normalizer): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (ffn): Sequential(\n",
       "                  (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "                  (1): ReLU()\n",
       "                  (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "                )\n",
       "                (norm2): Normalization(\n",
       "                  (normalizer): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (ffn2): TransformerFFN(\n",
       "              (ops): ModuleDict(\n",
       "                (norm1): Normalization(\n",
       "                  (normalizer): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (ffn): Sequential(\n",
       "                  (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "                  (1): ReLU()\n",
       "                  (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "                )\n",
       "                (norm2): Normalization(\n",
       "                  (normalizer): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): L2DDecoder(\n",
       "      (actor): FJSPActor(\n",
       "        (mlp): MLP(\n",
       "          (hidden_act): ReLU()\n",
       "          (out_act): Identity()\n",
       "          (lins): ModuleList(\n",
       "            (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "            (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "            (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          )\n",
       "          (input_norm): Identity()\n",
       "          (output_norm): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (baseline): WarmupBaseline(\n",
       "    (baseline): RolloutBaseline(\n",
       "      (policy): L2DPolicy(\n",
       "        (encoder): MultiEncoder(\n",
       "          (encoder_1): HetGNNEncoder(\n",
       "            (init_embedding): FJSPInitEmbedding(\n",
       "              (init_ops_embed): Linear(in_features=5, out_features=16, bias=False)\n",
       "              (pos_encoder): PositionalEncoding(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (init_ma_embed): Linear(in_features=1, out_features=16, bias=False)\n",
       "              (edge_embed): Linear(in_features=1, out_features=16, bias=False)\n",
       "            )\n",
       "            (layers): ModuleList(\n",
       "              (0-7): 8 x HetGNNBlock(\n",
       "                (hgnn1): HetGNNLayer(\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (hgnn2): HetGNNLayer(\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (ffn1): TransformerFFN(\n",
       "                  (ops): ModuleDict(\n",
       "                    (norm1): Normalization(\n",
       "                      (normalizer): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (ffn): Sequential(\n",
       "                      (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "                      (1): ReLU()\n",
       "                      (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "                    )\n",
       "                    (norm2): Normalization(\n",
       "                      (normalizer): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (ffn2): TransformerFFN(\n",
       "                  (ops): ModuleDict(\n",
       "                    (norm1): Normalization(\n",
       "                      (normalizer): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (ffn): Sequential(\n",
       "                      (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "                      (1): ReLU()\n",
       "                      (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "                    )\n",
       "                    (norm2): Normalization(\n",
       "                      (normalizer): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (encoder_2): HetGNNEncoder(\n",
       "            (init_embedding): AdditionalMachineInfoInitEmbedding(\n",
       "              (init_embed): Linear(in_features=1, out_features=16, bias=True)\n",
       "            )\n",
       "            (layers): ModuleList(\n",
       "              (0-3): 4 x HetGNNBlock(\n",
       "                (hgnn1): HetGNNLayer(\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (hgnn2): HetGNNLayer(\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (ffn1): TransformerFFN(\n",
       "                  (ops): ModuleDict(\n",
       "                    (norm1): Normalization(\n",
       "                      (normalizer): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (ffn): Sequential(\n",
       "                      (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "                      (1): ReLU()\n",
       "                      (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "                    )\n",
       "                    (norm2): Normalization(\n",
       "                      (normalizer): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (ffn2): TransformerFFN(\n",
       "                  (ops): ModuleDict(\n",
       "                    (norm1): Normalization(\n",
       "                      (normalizer): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (ffn): Sequential(\n",
       "                      (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "                      (1): ReLU()\n",
       "                      (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "                    )\n",
       "                    (norm2): Normalization(\n",
       "                      (normalizer): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (decoder): L2DDecoder(\n",
       "          (actor): FJSPActor(\n",
       "            (mlp): MLP(\n",
       "              (hidden_act): ReLU()\n",
       "              (out_act): Identity()\n",
       "              (lins): ModuleList(\n",
       "                (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "                (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "                (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "              )\n",
       "              (input_norm): Identity()\n",
       "              (output_norm): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (warmup_baseline): ExponentialBaseline()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d01fe75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-129.5156)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_new = new_env.reset(batch_size=64)\n",
    "\n",
    "res_new = model.to(\"cpu\")(td_new.to(\"cpu\"), env=new_env.to(\"cpu\"))\n",
    "\n",
    "res_new[\"reward\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb11378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
